{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Using Cohere Command and Cohere Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhadeep/Documents/PythonML/GPT/CohereRAGWithRerank/.venv-cohere-rag/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.7) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain.vectorstores.deeplake import DeepLake\n",
    "from langchain.document_loaders.pdf import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_cohere import CohereRerank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"481RrCzFPdfl0eTZWSLMApiw9TGWfjHAoK9BKerd\"\n",
    "TEMPERATURE = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = CohereEmbeddings(\n",
    "    model=\"embed-english-v3.0\",\n",
    "    cohere_api_key=API_KEY,\n",
    ")\n",
    "\n",
    "llm = ChatCohere(\n",
    "    model=\"command\",\n",
    "    cohere_api_key=API_KEY,\n",
    "    temperature=TEMPERATURE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "docstore = DeepLake(\n",
    "    dataset_path=\"deeplake_vstore\",\n",
    "    embedding=embeddings,\n",
    "    verbose=False,\n",
    "    num_workers=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/Apple-10K-2023.pdf\"\n",
    "loader = PyPDFLoader(file_path=file)\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "pages = loader.load()\n",
    "chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 358 embeddings in 1 batches of size 358::   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating 358 embeddings in 1 batches of size 358:: 100%|██████████| 1/1 [00:05<00:00,  5.80s/it]\n"
     ]
    }
   ],
   "source": [
    "_ = docstore.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in deeplake_vstore already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "docstore = DeepLake(\n",
    "    dataset_path=\"deeplake_vstore\",\n",
    "    embedding=embeddings,\n",
    "    verbose=False,\n",
    "    read_only=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "retriever = docstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"fetch_k\": 20,\n",
    "        \"k\": 10,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an intelligent chatbot that can answer user's queries. You will be provided with Relevant \n",
    "context based on the user's queries. Your task is to analyze user's query and generate response for \n",
    "the query from the context. Make sure to suggest one similar follow-up question based on the context \n",
    "for the user to ask.\n",
    "\n",
    "NEVER generate response to queries for which there is no or irrelevant context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT, \"verbose\": False}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=False,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the fiscal year highlights for second half of 2023?\"\n",
    "\n",
    "response = qa.invoke({\"query\": query})\n",
    "result = response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Company’s total net sales were $383.3 billion and net income was $97.0 billion during 2023. \n",
      "The Company’s total net sales decreased by 3% or $11.0 billion during 2023 compared to 2022. \n",
      "The weakness in foreign currencies relative to the U.S. dollar accounted for more than the entire year-over-year decrease in total net sales, which consisted primarily of lower net sales of Mac and iPhone, partially offset by higher net sales of Services. \n",
      "\n",
      "Based on the above context of Apple's financial performance, the second half of the fiscal year 2023 focused on the third and fourth quarters. These quarterly highlights include new product offerings and updates to the company's operating systems. \n",
      "\n",
      "The third quarter announced the following new products:\n",
      "\n",
      "•MacBook Air 15”\n",
      "•Mac Studio\n",
      "•Mac Pro\n",
      "•Apple Vision Pro™, the Company’s first spatial computer featuring its new visionOS™, expected to be available in early \n",
      "calendar year 2024\n",
      "•iOS 17, macOS Sonoma, iPadOS 17, tvOS 17 and watchOS 10, updates to the Company’s operating systems \n",
      "\n",
      "The fourth quarter announced the following new products: \n",
      "•iPhone 15, iPhone 15 Plus, iPhone 15 Pro and iPhone 15 Pro Max \n",
      "•Apple Watch Series 9 and Apple Watch Ultra 2 \n",
      "\n",
      "Based on this context, you should ask a follow-up question about the specific quarterly details of any of the newly announced products and their impact on the company's overall performance for the fiscal year 2023.\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QnA Using Cohere Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohere_rerank = CohereRerank(\n",
    "    cohere_api_key=API_KEY,\n",
    "    model=\"rerank-english-v3.0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Lake Dataset in deeplake_vstore already exists, loading from the storage\n"
     ]
    }
   ],
   "source": [
    "docstore = DeepLake(\n",
    "    dataset_path=\"deeplake_vstore\",\n",
    "    embedding=embeddings,\n",
    "    verbose=False,\n",
    "    read_only=True,\n",
    "    num_workers=4,\n",
    ")\n",
    "\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=cohere_rerank,\n",
    "    base_retriever=docstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"fetch_k\": 20,\n",
    "            \"k\": 15,\n",
    "        },\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an intelligent chatbot that can answer user's queries. You will be provided with Relevant \n",
    "context based on the user's queries. Your task is to analyze user's query and generate response for \n",
    "the query from the context. Make sure to suggest one similar follow-up question based on the context \n",
    "for the user to ask.\n",
    "\n",
    "NEVER generate response to queries for which there is no or irrelevant context.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT, \"verbose\": False}\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=compression_retriever,\n",
    "    return_source_documents=True,\n",
    "    verbose=False,\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the fiscal year highlights for second half of 2023?\"\n",
    "\n",
    "response = qa.invoke({\"query\": query})\n",
    "result = response[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Company’s total net sales were $383.3 billion and net income was $97.0 billion during 2023. \n",
      "The Company’s total net sales decreased 3% or $11.0 billion during 2023 compared to 2022. \n",
      "Significant announcements during the second half of fiscal year 2023, included:\n",
      "1. MacBook Pro 14”, MacBook Pro 16” and Mac mini;\n",
      "2. Second-generation HomePod;\n",
      "3. MacBook Air 15”, Mac Studio and Mac Pro;\n",
      "4. Apple Vision Pro™, the Company’s first spatial computer featuring its new visionOS™, expected to be available in early calendar year 2024; and\n",
      "5. iOS 17, macOS Sonoma, iPadOS 17, tvOS 17 and watchOS 10, updates to the Company’s operating systems. \n",
      "\n",
      "Based on the provided context, you can also ask the chatbot questions such as: \n",
      "\n",
      "1. How much did net sales decrease in the second half of 2023?\n",
      "2. What type of product announcements were made in the second half of 2023?\n",
      "3. When would you expect an announcement for Apple Vision Pro?\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhadeep/Documents/PythonML/GPT/CohereRAGWithRerank/.venv-cohere-rag/lib/python3.11/site-packages/deeplake/util/check_latest_version.py:32: UserWarning: A newer version of deeplake (3.9.3) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from src.ingestion import Ingestion\n",
    "\n",
    "ingestion = Ingestion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"data/Apple-10K-2023.pdf\"\n",
    "\n",
    "ingestion.create_and_add_embeddings(file_path=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
